{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ec3cd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, it's nice to meet you.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "load_dotenv(\"../.env\", override=True)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    openai_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"Say hello in one short sentence.\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f79ba9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"POST-SESSION  RESOURCES  \\nSession  4:  The  AI  Prototyper's  Sandbox:  Mastering  Google  AI  Studio  \\n  \\nThis\\n \\nresource\\n \\npack\\n \\nprovides\\n \\nthe\\n \\ntools,\\n \\ntemplates,\\n \\nand\\n \\nreference\\n \\nmaterial\\n \\nto\\n \\nhelp\\n \\nyou\\n \\ndeepen\\n \\nyour\\n \\nunderstanding\\n \\nof\\n \\ntodayâ€™s\\n \\nconcepts\\n \\nand\\n \\napply\\n \\nthem\\n \\ndir\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_pdf(pdf_path: str):\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    return loader.load()\n",
    "docs = load_pdf(\"/Users/emmanuelreddy/Desktop/rag2/rag-grok/data/POST-SESSION RESOURCES - S4.pdf\")\n",
    "docs[0].page_content[:300]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c4a5005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def chunk_documents(documents):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    return splitter.split_documents(documents)\n",
    "chunks = chunk_documents(docs)\n",
    "len(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed04bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "vector_db = FAISS.from_documents(chunks, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "518e65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(vector_db, query, k=4):\n",
    "    retriever = vector_db.as_retriever(search_kwargs={\"k\": k})\n",
    "    return retriever.invoke(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79f84a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.  Prompt  Templates    Session 4 Prompt Templates.pdf Leverage  these  prompting  resources  for  a  head  start  on  structured,  high-quality  outputs  \\n4.  Demo  Inputs  Used  in  Session'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query = \"What is the main topic of the document?\"\n",
    "retrieved_docs = retrieve_context(vector_db, query)\n",
    "\n",
    "retrieved_docs[0].page_content[:300]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fc8dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query, retrieved_docs):\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful assistant.\n",
    "Answer ONLY using the provided context.\n",
    "If the answer is not present, say:\n",
    "\"Answer not found in the document.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b13be2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main topic of the document is Session 4 of a course or training program, specifically focused on \"The AI Prototyper's Sandbox: Mastering Google AI Studio\" and using Gemini AI Studio for AI product engineering.\n"
     ]
    }
   ],
   "source": [
    "answer = generate_answer(query, retrieved_docs)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bfaab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline(pdf_path, query):\n",
    "    docs = load_pdf(pdf_path)\n",
    "    chunks = chunk_documents(docs)\n",
    "    vector_db = FAISS.from_documents(chunks, embeddings)\n",
    "    retrieved_docs = retrieve_context(vector_db, query)\n",
    "    return generate_answer(query, retrieved_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25850629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The objective of this document is to provide guidance on leveraging prompting resources for high-quality outputs, managing AI behavior, and implementing best practices for AI development, including transparency, security, and human oversight, to ensure responsible and effective AI usage.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_pipeline(\"../data/POST-SESSION RESOURCES - S4.pdf\", \"Explain the objective of this document\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
